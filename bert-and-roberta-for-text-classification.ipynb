{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:27.925618Z","iopub.execute_input":"2024-06-08T04:43:27.928597Z","iopub.status.idle":"2024-06-08T04:43:34.820785Z","shell.execute_reply.started":"2024-06-08T04:43:27.928551Z","shell.execute_reply":"2024-06-08T04:43:34.819747Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_imdb_data(data_file):\n    df = pd.read_csv(data_file)\n    texts = df['review'].tolist()\n    labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]\n    return texts, labels","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:34.822637Z","iopub.execute_input":"2024-06-08T04:43:34.823137Z","iopub.status.idle":"2024-06-08T04:43:34.828877Z","shell.execute_reply.started":"2024-06-08T04:43:34.823107Z","shell.execute_reply":"2024-06-08T04:43:34.827799Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_file = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\ntexts, labels = load_imdb_data(data_file)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:34.830113Z","iopub.execute_input":"2024-06-08T04:43:34.830470Z","iopub.status.idle":"2024-06-08T04:43:36.119951Z","shell.execute_reply.started":"2024-06-08T04:43:34.830442Z","shell.execute_reply":"2024-06-08T04:43:36.118893Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Bert","metadata":{}},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n            self.texts = texts\n            self.labels = labels\n            self.tokenizer = tokenizer\n            self.max_length = max_length\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        return {\n            'input_ids': encoding['input_ids'].flatten(), \n            'attention_mask': encoding['attention_mask'].flatten(), \n            'label': torch.tensor(label)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:55.142725Z","iopub.execute_input":"2024-06-08T04:43:55.143369Z","iopub.status.idle":"2024-06-08T04:43:55.150836Z","shell.execute_reply.started":"2024-06-08T04:43:55.143338Z","shell.execute_reply":"2024-06-08T04:43:55.149684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes):\n        super(BERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(0.1)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n            pooled_output = outputs.pooler_output\n            x = self.dropout(pooled_output)\n            logits = self.fc(x)\n            return logits","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:55.370395Z","iopub.execute_input":"2024-06-08T04:43:55.371088Z","iopub.status.idle":"2024-06-08T04:43:55.377830Z","shell.execute_reply.started":"2024-06-08T04:43:55.371057Z","shell.execute_reply":"2024-06-08T04:43:55.376645Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:56.014658Z","iopub.execute_input":"2024-06-08T04:43:56.015057Z","iopub.status.idle":"2024-06-08T04:43:56.022784Z","shell.execute_reply.started":"2024-06-08T04:43:56.015025Z","shell.execute_reply":"2024-06-08T04:43:56.021599Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:56.415059Z","iopub.execute_input":"2024-06-08T04:43:56.416016Z","iopub.status.idle":"2024-06-08T04:43:56.423916Z","shell.execute_reply.started":"2024-06-08T04:43:56.415981Z","shell.execute_reply":"2024-06-08T04:43:56.422845Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        return \"positive\" if preds.item() == 1 else \"negative\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:56.822784Z","iopub.execute_input":"2024-06-08T04:43:56.823640Z","iopub.status.idle":"2024-06-08T04:43:56.830367Z","shell.execute_reply.started":"2024-06-08T04:43:56.823608Z","shell.execute_reply":"2024-06-08T04:43:56.829255Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Set up parameters\nbert_model_name = 'bert-base-uncased'\nnum_classes = 2\nmax_length = 128\nbatch_size = 16\nnum_epochs = 4\nlearning_rate = 2e-5","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:57.214222Z","iopub.execute_input":"2024-06-08T04:43:57.215055Z","iopub.status.idle":"2024-06-08T04:43:57.219421Z","shell.execute_reply.started":"2024-06-08T04:43:57.215023Z","shell.execute_reply":"2024-06-08T04:43:57.218362Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:57.878503Z","iopub.execute_input":"2024-06-08T04:43:57.878879Z","iopub.status.idle":"2024-06-08T04:43:57.913507Z","shell.execute_reply.started":"2024-06-08T04:43:57.878848Z","shell.execute_reply":"2024-06-08T04:43:57.912463Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(bert_model_name)\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:58.606470Z","iopub.execute_input":"2024-06-08T04:43:58.607155Z","iopub.status.idle":"2024-06-08T04:43:58.761423Z","shell.execute_reply.started":"2024-06-08T04:43:58.607120Z","shell.execute_reply":"2024-06-08T04:43:58.760404Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BERTClassifier(bert_model_name, num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:43:59.438786Z","iopub.execute_input":"2024-06-08T04:43:59.439554Z","iopub.status.idle":"2024-06-08T04:44:02.130822Z","shell.execute_reply.started":"2024-06-08T04:43:59.439499Z","shell.execute_reply":"2024-06-08T04:44:02.129742Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ecb3b72157847f8af6d316f447bc5f8"}},"metadata":{}}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:44:04.007026Z","iopub.execute_input":"2024-06-08T04:44:04.007910Z","iopub.status.idle":"2024-06-08T04:44:04.018929Z","shell.execute_reply.started":"2024-06-08T04:44:04.007874Z","shell.execute_reply":"2024-06-08T04:44:04.017947Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, train_dataloader, optimizer, scheduler, device)\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-06-07T13:03:18.718615Z","iopub.execute_input":"2024-06-07T13:03:18.718940Z","iopub.status.idle":"2024-06-07T14:04:58.769633Z","shell.execute_reply.started":"2024-06-07T13:03:18.718916Z","shell.execute_reply":"2024-06-07T14:04:58.768562Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Epoch 1/4\nValidation Accuracy: 0.8899\n              precision    recall  f1-score   support\n\n           0       0.90      0.88      0.89      4961\n           1       0.88      0.90      0.89      5039\n\n    accuracy                           0.89     10000\n   macro avg       0.89      0.89      0.89     10000\nweighted avg       0.89      0.89      0.89     10000\n\nEpoch 2/4\nValidation Accuracy: 0.8978\n              precision    recall  f1-score   support\n\n           0       0.89      0.90      0.90      4961\n           1       0.90      0.89      0.90      5039\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n\nEpoch 3/4\nValidation Accuracy: 0.8955\n              precision    recall  f1-score   support\n\n           0       0.88      0.91      0.90      4961\n           1       0.91      0.88      0.89      5039\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n\nEpoch 4/4\nValidation Accuracy: 0.8983\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90      4961\n           1       0.90      0.90      0.90      5039\n\n    accuracy                           0.90     10000\n   macro avg       0.90      0.90      0.90     10000\nweighted avg       0.90      0.90      0.90     10000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"bert_classifier.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:23:37.392370Z","iopub.execute_input":"2024-06-07T14:23:37.393134Z","iopub.status.idle":"2024-06-07T14:23:38.003777Z","shell.execute_reply.started":"2024-06-07T14:23:37.393102Z","shell.execute_reply":"2024-06-07T14:23:38.002889Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# Test sentiment prediction\ntest_text = \"The movie was great and I really enjoyed the performances of the actors.\"\nsentiment = predict_sentiment(test_text, model, tokenizer, device)\nprint(\"The movie was great and I really enjoyed the performances of the actors.\")\nprint(f\"Predicted sentiment: {sentiment}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-07T14:24:11.886357Z","iopub.execute_input":"2024-06-07T14:24:11.886697Z","iopub.status.idle":"2024-06-07T14:24:11.905436Z","shell.execute_reply.started":"2024-06-07T14:24:11.886672Z","shell.execute_reply":"2024-06-07T14:24:11.904596Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"The movie was great and I really enjoyed the performances of the actors.\nPredicted sentiment: positive\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# RoBerta","metadata":{}},{"cell_type":"markdown","source":"### Custom dataset","metadata":{}},{"cell_type":"code","source":"class SentimentData(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.text = texts\n        self.targets = labels\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:44:21.617831Z","iopub.execute_input":"2024-06-08T04:44:21.618197Z","iopub.status.idle":"2024-06-08T04:44:21.627184Z","shell.execute_reply.started":"2024-06-08T04:44:21.618167Z","shell.execute_reply":"2024-06-08T04:44:21.626175Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaModel\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\ntrain_dataset = SentimentData(train_texts, train_labels, tokenizer, max_length)\nval_dataset = SentimentData(val_texts, val_labels, tokenizer, max_length)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:45:25.256789Z","iopub.execute_input":"2024-06-08T04:45:25.257529Z","iopub.status.idle":"2024-06-08T04:45:27.234135Z","shell.execute_reply.started":"2024-06-08T04:45:25.257496Z","shell.execute_reply":"2024-06-08T04:45:27.233136Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68fcbb4343954cdd868f441cd3480d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f747a5b9cc48ea8f3954fcd1b82ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e729082aa5748828280b25e061f9429"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7648267ec74451184851e98502f5408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"082703781b8b4622828109644ab9b124"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Model RoBerta","metadata":{}},{"cell_type":"code","source":"  \nclass RoBERTaClassifier(torch.nn.Module):\n    def __init__(self, num_classes):\n        super(RoBERTaClassifier, self).__init__()\n        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.3)\n        self.classifier = torch.nn.Linear(768, num_classes)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.ReLU()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:45:27.673349Z","iopub.execute_input":"2024-06-08T04:45:27.673993Z","iopub.status.idle":"2024-06-08T04:45:27.683505Z","shell.execute_reply.started":"2024-06-08T04:45:27.673958Z","shell.execute_reply":"2024-06-08T04:45:27.682519Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = RoBERTaClassifier(num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:45:32.153040Z","iopub.execute_input":"2024-06-08T04:45:32.153943Z","iopub.status.idle":"2024-06-08T04:45:34.978216Z","shell.execute_reply.started":"2024-06-08T04:45:32.153906Z","shell.execute_reply":"2024-06-08T04:45:34.977419Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258ec7c85dd54c598df9b4c75052d56a"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Defining the training function on the 80% of the dataset for tuning the distilbert model\n\n# def train(model, data_loader, optimizer, scheduler, device):\n#     model.train()\n#     for batch in data_loader:\n#         optimizer.zero_grad()\n#         input_ids = batch['input_ids'].to(device)\n#         attention_mask = batch['attention_mask'].to(device)\n#         labels = batch['label'].to(device)\n#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n#         loss = nn.CrossEntropyLoss()(outputs, labels)\n#         loss.backward()\n#         optimizer.step()\n#         scheduler.step()\n        \n\ndef train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    \n    for batch in data_loader:\n        optimizer.zero_grad()\n        \n        ids = batch['ids'].to(device, dtype = torch.long)\n        mask = batch['mask'].to(device, dtype = torch.long)\n        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n        targets = batch['targets'].to(device, dtype = torch.long)\n\n        outputs = model(ids, mask, token_type_ids)\n        loss =  nn.CrossEntropyLoss()(outputs, targets)\n        \n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:45:34.979817Z","iopub.execute_input":"2024-06-08T04:45:34.980106Z","iopub.status.idle":"2024-06-08T04:45:34.987826Z","shell.execute_reply.started":"2024-06-08T04:45:34.980081Z","shell.execute_reply":"2024-06-08T04:45:34.986668Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def calcuate_accuracy(preds, targets):\n    for i, j in zip(preds, targets):\n        n_correct = (preds==targets).sum().item()\n    return n_correct","metadata":{"execution":{"iopub.status.busy":"2024-06-08T04:59:49.515226Z","iopub.execute_input":"2024-06-08T04:59:49.515630Z","iopub.status.idle":"2024-06-08T04:59:49.520362Z","shell.execute_reply.started":"2024-06-08T04:59:49.515596Z","shell.execute_reply":"2024-06-08T04:59:49.519425Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            ids = batch['ids'].to(device, dtype = torch.long)\n            mask = batch['mask'].to(device, dtype = torch.long)\n            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n            targets = batch['targets'].to(device, dtype = torch.long)\n            \n            outputs = model(ids, mask, token_type_ids).squeeze()\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(targets.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)\n\n# def evaluate(model, data_loader, device):\n#     model.eval()\n#     n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n#     actual_labels = []\n#     predictions = []\n#     with torch.no_grad():\n#         for _, data in tqdm(enumerate(data_loader, 0)):\n#             ids = data['ids'].to(device, dtype = torch.long)\n#             mask = data['mask'].to(device, dtype = torch.long)\n#             token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n#             targets = data['targets'].to(device, dtype = torch.long)\n            \n#             outputs = model(ids, mask, token_type_ids).squeeze()\n#             loss = nn.CrossEntropyLoss()(outputs, targets)\n#             tr_loss += loss.item()\n#             big_val, big_idx = torch.max(outputs.data, dim=1)\n            \n#             predictions.extend(big_idx)\n#             actual_labels.extend(labels)\n\n            \n#             n_correct += calcuate_accuracy(big_idx, targets)\n\n#             nb_tr_steps += 1\n#             nb_tr_examples+=targets.size(0)\n            \n#     epoch_loss = tr_loss/nb_tr_steps\n#     epoch_accu = (n_correct*100)/nb_tr_examples\n    \n#     return epoch_accu, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-06-08T05:34:35.537027Z","iopub.execute_input":"2024-06-08T05:34:35.537413Z","iopub.status.idle":"2024-06-08T05:34:35.546724Z","shell.execute_reply.started":"2024-06-08T05:34:35.537382Z","shell.execute_reply":"2024-06-08T05:34:35.545794Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T05:34:36.259815Z","iopub.execute_input":"2024-06-08T05:34:36.260788Z","iopub.status.idle":"2024-06-08T05:34:36.270019Z","shell.execute_reply.started":"2024-06-08T05:34:36.260753Z","shell.execute_reply":"2024-06-08T05:34:36.269166Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, train_dataloader, optimizer, scheduler, device)\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T05:34:36.820201Z","iopub.execute_input":"2024-06-08T05:34:36.820805Z","iopub.status.idle":"2024-06-08T06:16:13.364625Z","shell.execute_reply.started":"2024-06-08T05:34:36.820776Z","shell.execute_reply":"2024-06-08T06:16:13.363596Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/4\nValidation Accuracy: 0.9139\n              precision    recall  f1-score   support\n\n           0       0.93      0.90      0.91      4961\n           1       0.90      0.93      0.92      5039\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n\nEpoch 2/4\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.9115\n              precision    recall  f1-score   support\n\n           0       0.93      0.89      0.91      4961\n           1       0.90      0.93      0.91      5039\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n\nEpoch 3/4\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.9110\n              precision    recall  f1-score   support\n\n           0       0.91      0.92      0.91      4961\n           1       0.92      0.91      0.91      5039\n\n    accuracy                           0.91     10000\n   macro avg       0.91      0.91      0.91     10000\nweighted avg       0.91      0.91      0.91     10000\n\nEpoch 4/4\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.9163\n              precision    recall  f1-score   support\n\n           0       0.92      0.91      0.92      4961\n           1       0.91      0.92      0.92      5039\n\n    accuracy                           0.92     10000\n   macro avg       0.92      0.92      0.92     10000\nweighted avg       0.92      0.92      0.92     10000\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- RoBERTa: https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb#scrollTo=mhqvtY2SIup7\n- Bert:https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"roberta_classifier.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T06:18:27.056271Z","iopub.execute_input":"2024-06-08T06:18:27.056996Z","iopub.status.idle":"2024-06-08T06:18:27.803978Z","shell.execute_reply.started":"2024-06-08T06:18:27.056960Z","shell.execute_reply":"2024-06-08T06:18:27.802967Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}